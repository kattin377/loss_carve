{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "906cd05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss函数的表现形式：\n",
    "\n",
    "# 目标得到good-fit 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a188025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 环境配置\n",
    "# conda create -n tf_env python=3.10\n",
    "# conda activate tf_env\n",
    "# pip install tensorflow==2.13\n",
    "# pip install \"pyOpenSSL<25\"\n",
    "\n",
    "\n",
    "# conda install ipykernel  #if run in cell\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad6a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "from tensorflow.keras.models import Model  # type: ignore\n",
    "from tensorflow.keras.preprocessing import sequence # type: ignore\n",
    "from tensorflow.keras.layers import Input # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Activation# type: ignore\n",
    "from tensorflow.keras.layers import Embedding # type: ignore\n",
    "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D # type: ignore\n",
    "from tensorflow.keras.datasets import imdb # type: ignore\n",
    "from tensorflow.keras import optimizers # type: ignore\n",
    "import matplotlib # type: ignore\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52fca3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "batch_size = 32\n",
    "embedding_dims = 200\n",
    "filters = 250\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8ecb88d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# pad dataset to a maximum review length in words\n",
    "max_words = 500\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_words)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c2f0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "sentence = Input(batch_shape=(None, max_words), dtype='int32', name='sentence')\n",
    "embedding_layer = Embedding(top_words, embedding_dims, input_length=max_words)\n",
    "sent_embed = embedding_layer(sentence)\n",
    "conv_layer = Conv1D(filters, kernel_size, padding='valid', activation='relu')\n",
    "sent_conv = conv_layer(sent_embed)\n",
    "sent_pooling = GlobalMaxPooling1D()(sent_conv)\n",
    "sent_repre = Dense(250)(sent_pooling)\n",
    "sent_repre = Activation('relu')(sent_repre)\n",
    "sent_repre = Dense(1)(sent_repre)\n",
    "pred = Activation('sigmoid')(sent_repre)\n",
    "model = Model(inputs=sentence, outputs=pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b2fd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#underfit\n",
    "epochs = 30\n",
    "sgd = optimizers.SGD(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22e7c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "782/782 [==============================] - 62s 79ms/step - loss: 0.6927 - accuracy: 0.5138 - val_loss: 0.6920 - val_accuracy: 0.5794\n",
      "Epoch 2/30\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.6915 - accuracy: 0.5399 - val_loss: 0.6907 - val_accuracy: 0.6070\n",
      "Epoch 3/30\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.6898 - accuracy: 0.5751 - val_loss: 0.6888 - val_accuracy: 0.6192\n",
      "Epoch 4/30\n",
      "782/782 [==============================] - 58s 75ms/step - loss: 0.6873 - accuracy: 0.6198 - val_loss: 0.6855 - val_accuracy: 0.6845\n",
      "Epoch 5/30\n",
      "782/782 [==============================] - 58s 74ms/step - loss: 0.6824 - accuracy: 0.6605 - val_loss: 0.6785 - val_accuracy: 0.6820\n",
      "Epoch 6/30\n",
      "782/782 [==============================] - 58s 75ms/step - loss: 0.6705 - accuracy: 0.6627 - val_loss: 0.6600 - val_accuracy: 0.6264\n",
      "Epoch 7/30\n",
      "782/782 [==============================] - 58s 74ms/step - loss: 0.6478 - accuracy: 0.6289 - val_loss: 0.6373 - val_accuracy: 0.6196\n",
      "Epoch 8/30\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 0.6314 - accuracy: 0.6272 - val_loss: 0.6249 - val_accuracy: 0.6272\n",
      "Epoch 9/30\n",
      "782/782 [==============================] - 60s 76ms/step - loss: 0.6175 - accuracy: 0.6517 - val_loss: 0.6099 - val_accuracy: 0.6909\n",
      "Epoch 10/30\n",
      "782/782 [==============================] - 59s 76ms/step - loss: 0.5976 - accuracy: 0.6867 - val_loss: 0.5871 - val_accuracy: 0.7097\n",
      "Epoch 11/30\n",
      "782/782 [==============================] - 60s 77ms/step - loss: 0.5714 - accuracy: 0.7142 - val_loss: 0.5600 - val_accuracy: 0.7258\n",
      "Epoch 12/30\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 0.5428 - accuracy: 0.7351 - val_loss: 0.5339 - val_accuracy: 0.7367\n",
      "Epoch 13/30\n",
      "782/782 [==============================] - 59s 76ms/step - loss: 0.5197 - accuracy: 0.7485 - val_loss: 0.5213 - val_accuracy: 0.7418\n",
      "Epoch 14/30\n",
      "782/782 [==============================] - 59s 76ms/step - loss: 0.4982 - accuracy: 0.7619 - val_loss: 0.4944 - val_accuracy: 0.7618\n",
      "Epoch 15/30\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.4743 - accuracy: 0.7773 - val_loss: 0.4740 - val_accuracy: 0.7738\n",
      "Epoch 16/30\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.4487 - accuracy: 0.7939 - val_loss: 0.4513 - val_accuracy: 0.7877\n",
      "Epoch 17/30\n",
      "782/782 [==============================] - 92s 117ms/step - loss: 0.4244 - accuracy: 0.8070 - val_loss: 0.4315 - val_accuracy: 0.7980\n",
      "Epoch 18/30\n",
      "782/782 [==============================] - 62s 79ms/step - loss: 0.4008 - accuracy: 0.8202 - val_loss: 0.4562 - val_accuracy: 0.7800\n",
      "Epoch 19/30\n",
      "782/782 [==============================] - 63s 80ms/step - loss: 0.3758 - accuracy: 0.8373 - val_loss: 0.4020 - val_accuracy: 0.8153\n",
      "Epoch 20/30\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.3524 - accuracy: 0.8484 - val_loss: 0.4317 - val_accuracy: 0.7935\n",
      "Epoch 21/30\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.3298 - accuracy: 0.8630 - val_loss: 0.3614 - val_accuracy: 0.8365\n",
      "Epoch 22/30\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 0.3113 - accuracy: 0.8715 - val_loss: 0.3522 - val_accuracy: 0.8404\n",
      "Epoch 23/30\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 0.2939 - accuracy: 0.8810 - val_loss: 0.3601 - val_accuracy: 0.8370\n",
      "Epoch 24/30\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.2777 - accuracy: 0.8890 - val_loss: 0.3287 - val_accuracy: 0.8534\n",
      "Epoch 25/30\n",
      "782/782 [==============================] - 62s 80ms/step - loss: 0.2626 - accuracy: 0.8959 - val_loss: 0.3250 - val_accuracy: 0.8562\n",
      "Epoch 26/30\n",
      "782/782 [==============================] - 63s 80ms/step - loss: 0.2473 - accuracy: 0.9025 - val_loss: 0.3204 - val_accuracy: 0.8591\n",
      "Epoch 27/30\n",
      "782/782 [==============================] - 63s 81ms/step - loss: 0.2342 - accuracy: 0.9083 - val_loss: 0.3094 - val_accuracy: 0.8650\n",
      "Epoch 28/30\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.2220 - accuracy: 0.9162 - val_loss: 0.3118 - val_accuracy: 0.8626\n",
      "Epoch 29/30\n",
      "782/782 [==============================] - 63s 81ms/step - loss: 0.2077 - accuracy: 0.9206 - val_loss: 0.3081 - val_accuracy: 0.8647\n",
      "Epoch 30/30\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.1953 - accuracy: 0.9289 - val_loss: 0.3164 - val_accuracy: 0.8621\n",
      "Accuracy: 86.21%\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size,\n",
    "          epochs=epochs, verbose=1, validation_data=(x_test, y_test))\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cebafc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "plt.plot(loss, label='loss')\n",
    "plt.plot(val_loss, label='val_loss')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'valid'], loc='upper left')\n",
    "plt.savefig('./loss.png')\n",
    "# plt.show ()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
